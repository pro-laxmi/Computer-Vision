# ğŸ”¢ MNIST Digit Recognizer - Vision Transformer Web App

A beautiful, interactive web application for recognizing handwritten digits using a Vision Transformer model trained on MNIST dataset.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0-red)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ§  Model Architecture

### Vision Transformer Model Architecture

```
INPUT: 28Ã—28 Grayscale Image
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patch Embedding              â”‚
â”‚  - Conv2d Layer               â”‚
â”‚  - Kernel: 7Ã—7                â”‚
â”‚  - Stride: 7                  â”‚
â”‚  - Output: (1, 16, 128)       â”‚
â”‚    (1 batch, 16 patches,      â”‚
â”‚     128 embedding dims)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Add CLS Token                â”‚
â”‚  - Prepend learnable token    â”‚
â”‚  - Shape: (1, 17, 128)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Add Positional Embedding     â”‚
â”‚  - Learnable positional       â”‚
â”‚    embeddings                 â”‚
â”‚  - Shape: (1, 17, 128)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  TRANSFORMER BLOCK  Ã—6   â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ Layer Norm         â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚            â–¼             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ Multi-Head Attn    â”‚  â”‚
  â”‚  â”‚ (8 heads)          â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚            â–¼             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ Add Residual       â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚            â–¼             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ Layer Norm         â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚            â–¼             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ MLP (FC+ReLU+FC)   â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚            â–¼             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ Add Residual       â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚            â–¼             â”‚
  â”‚  Output: (1, 17, 128)    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extract CLS Token            â”‚
â”‚  - Take first token only      â”‚
â”‚  - Shape: (1, 128)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLP Head                     â”‚
â”‚  - Layer Norm                 â”‚
â”‚  - FC: 128 â†’ 256              â”‚
â”‚  - FC: 256 â†’ 128              â”‚
â”‚  - Shape: (1, 128)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
OUTPUT: Logits for 10 digits
        Shape: (1, 10)
```

---

## ğŸ¯ Demo

### Features:
1. **Draw Tab** - Sketch digits with your mouse
2. **Upload Tab** - Upload digit images from files
3. **About Tab** - Learn about the model and tips

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- pip package manager
- Trained model file: `trained_vit_mnist.pth`

### Installation

1. **Clone or download the repository**
   ```bash
   git clone https://github.com/YOUR_USERNAME/mnist-digit-recognizer.git
   cd mnist-digit-recognizer
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements_web.txt
   ```

3. **Make sure you have the trained model**
   ```bash
   # The trained_vit_mnist.pth should be in the same directory
   ls trained_vit_mnist.pth
   ```

4. **Run the app**
   ```bash
   streamlit run vit_web_app.py
   ```

5. **Access the app**
   - Open your browser to: `http://localhost:8501`

---

## ğŸ“¦ Installation Details

### For Windows Users:
```powershell
# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install packages
pip install -r requirements_web.txt

# Run app
streamlit run vit_web_app.py
```

### For Mac/Linux Users:
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install packages
pip install -r requirements_web.txt

# Run app
streamlit run vit_web_app.py
```

---

## ğŸ—ï¸ Project Structure

```
mnist-digit-recognizer/
â”œâ”€â”€ vit_web_app.py                 # Main Streamlit app
â”œâ”€â”€ vit_drawing_gui.py             # Desktop GUI version
â”œâ”€â”€ trained_vit_mnist.pth          # Trained model weights
â”œâ”€â”€ requirements_web.txt           # Web app dependencies
â”œâ”€â”€ DEPLOYMENT_GUIDE.md            # Detailed deployment guide
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml               # Streamlit configuration
â””â”€â”€ CNN_and_Vision/06_vision_transformer_from_scratch.ipynb  # Training notebook
```

---


## ğŸ’¡ Usage Tips

### For Best Results:
1. **Draw clearly** - Use contrasting colors (dark on light)
2. **Center the digit** - Place digit in the middle of canvas
3. **Full size** - Make the digit reasonably large
4. **Single digit** - Only one digit per image
5. **Clear image** - Avoid smudges or multiple strokes

### Example:
- Good: Clear, centered digit in a 28Ã—28 MNIST style
- Bad: Multiple digits, very small, at edges, faint/light

---

## ğŸ› ï¸ Customization

### Modify Appearance:
Edit the custom CSS in `vit_web_app.py`:
```python
st.markdown("""
<style>
.main-title {
    color: #YOUR_COLOR;
    font-size: 3em;
}
</style>
""", unsafe_allow_html=True)
```

### Change Model Hyperparameters:
Edit the `model_config` in `vit_web_app.py`:
```python
model_config = {
    'img_size': 28,
    'patch_size': 7,
    'embed_dim': 128,  # Change this
    'depth': 6,
    # ... other params
}
```

---

## ğŸ“Š Performance

### Inference Time:
- **CPU**: ~100-200ms
- **GPU (CUDA)**: ~20-50ms

### Accuracy:
- Model trained to achieve ~97-99% accuracy on MNIST test set

### App Response:
- Drawing prediction: <1 second
- Upload prediction: 1-2 seconds

---

## ğŸ› Troubleshooting

### Issue: "ModuleNotFoundError: No module named 'streamlit'"
**Solution:**
```bash
pip install streamlit
```

### Issue: "trained_vit_mnist.pth not found"
**Solution:**
- Train the model first using the Jupyter notebook
- Or download from project releases
- Make sure file is in the same directory as `vit_web_app.py`

### Issue: App is very slow
**Solution:**
- First load takes 10-30 seconds on free tier
- Subsequent requests are faster
- GPU deployment is faster

### Issue: Drawing canvas not working
**Solution:**
```bash
pip install streamlit-drawable-canvas
```

### Issue: "CUDA out of memory"
**Solution:**
```python
# In vit_web_app.py, change:
device = torch.device('cpu')  # Force CPU
```

---

## ğŸ“š Learning Resources

- **Streamlit Docs**: https://docs.streamlit.io
- **Vision Transformer Paper**: https://arxiv.org/abs/2010.11929
- **MNIST Dataset**: http://yann.lecun.com/exdb/mnist/
- **PyTorch Docs**: https://pytorch.org/docs/
- **Vizuara Playlist**: https://www.youtube.com/playlist?list=PLPTV0NXA_ZSgmWYoSpY_2EJzPJjkke4Az

---

## ğŸ¤ Contributing

Contributions are welcome! Here are some ideas:
- Add batch prediction
- Implement webcam input
- Add more datasets (CIFAR-10, etc.)
- Improve UI/UX
- Add model comparison
- Performance optimizations

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¨â€ğŸ’» Author

Created with â¤ï¸ by Laxmidhar Panda.

---

## ğŸ™ Acknowledgments

- Original MNIST dataset by Yann LeCun
- Vision Transformer paper by Google Research
- Vizuara for it's awesome and indeapth video leactures on this
- Streamlit for amazing ML web framework

---

**Enjoy tinkering! âœ¨**